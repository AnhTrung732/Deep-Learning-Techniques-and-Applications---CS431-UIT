{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Get data","metadata":{}},{"cell_type":"code","source":"!pip install gdown\n!pip install pyvi","metadata":{"execution":{"iopub.status.busy":"2023-05-29T13:27:49.172626Z","iopub.execute_input":"2023-05-29T13:27:49.173275Z","iopub.status.idle":"2023-05-29T13:28:15.009323Z","shell.execute_reply.started":"2023-05-29T13:27:49.173238Z","shell.execute_reply":"2023-05-29T13:28:15.008150Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.11.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.28.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.64.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.1.1)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting pyvi\n  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting sklearn-crfsuite\n  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pyvi) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.2.0)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.23.5)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (3.1.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.9.3)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nCollecting python-crfsuite>=0.8.3\n  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (1.16.0)\nRequirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (4.64.1)\nInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\nSuccessfully installed python-crfsuite-0.9.9 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!gdown 10U3ShbGdakYKIpwvoLRzJEOP_zRRy3zT","metadata":{"execution":{"iopub.status.busy":"2023-05-29T13:28:15.012350Z","iopub.execute_input":"2023-05-29T13:28:15.012773Z","iopub.status.idle":"2023-05-29T13:28:17.588291Z","shell.execute_reply.started":"2023-05-29T13:28:15.012732Z","shell.execute_reply":"2023-05-29T13:28:17.587149Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=10U3ShbGdakYKIpwvoLRzJEOP_zRRy3zT\nTo: /kaggle/working/UIT-VSMEC-20230520T124243Z-001.zip\n100%|█████████████████████████████████████████| 319k/319k [00:00<00:00, 113MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!unzip /kaggle/working/UIT-VSMEC-20230520T124243Z-001.zip","metadata":{"execution":{"iopub.status.busy":"2023-05-29T13:28:17.590579Z","iopub.execute_input":"2023-05-29T13:28:17.591283Z","iopub.status.idle":"2023-05-29T13:28:18.554801Z","shell.execute_reply.started":"2023-05-29T13:28:17.591244Z","shell.execute_reply":"2023-05-29T13:28:18.553620Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Archive:  /kaggle/working/UIT-VSMEC-20230520T124243Z-001.zip\n  inflating: UIT-VSMEC/valid_nor_811.xlsx  \n  inflating: UIT-VSMEC/test_nor_811.xlsx  \n  inflating: UIT-VSMEC/train_nor_811.xlsx  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import Files and Libraries","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install tensorflow_text\n!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-05-29T13:29:05.193567Z","iopub.execute_input":"2023-05-29T13:29:05.194259Z","iopub.status.idle":"2023-05-29T13:29:28.645808Z","shell.execute_reply.started":"2023-05-29T13:29:05.194224Z","shell.execute_reply":"2023-05-29T13:29:28.644512Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# nltk imports\nfrom nltk.tokenize import word_tokenize  # tokenize the text == the text is splitted into words in list\nfrom nltk.corpus import stopwords  # this contain common stop words that has no effect in analysis\nfrom nltk.stem import WordNetLemmatizer  # Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item\n\n# sklearn imports\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer  # bags of words and TF IDF\nfrom sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix, make_scorer  # classification Metrics\nfrom sklearn.naive_bayes import MultinomialNB  # Multiclassification\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import svm\nfrom sklearn.model_selection import StratifiedKFold  # For stratified splitting (helpful in imbalanced data)\nfrom sklearn.preprocessing import LabelBinarizer  # for Categorical features\nfrom sklearn.model_selection import GridSearchCV  # for tuning parameters\nfrom sklearn.model_selection import train_test_split  # splitting dataset\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn import metrics\nfrom sklearn import pipeline\nfrom sklearn import linear_model\n\n# gensim imports\nfrom gensim.models import KeyedVectors  # to save and load vectors\nimport string\nimport re\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nimport catboost as cbt\n\n# tensorflow and keras\nimport keras\nfrom keras import backend as K\nfrom tensorflow.keras.layers import Embedding\nfrom keras.models import Model\nfrom keras.preprocessing.text import Tokenizer\n#from keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing import sequence, text\nfrom keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, GRU\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\nfrom keras.utils import np_utils\nfrom keras.callbacks import EarlyStopping , ReduceLROnPlateau\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_text as text\nimport codecs\nimport pickle\n\nfrom pyvi import ViTokenizer\nimport gensim\n\n# Hugging Face Transformers\nfrom transformers import (pipeline , BertTokenizer,\n                          TFBertForSequenceClassification,\n                          InputExample, InputFeatures , \n                         AutoTokenizer, TFAutoModelForSequenceClassification,\n                         TFRobertaModel, TFGPT2Model, RobertaTokenizer, GPT2Tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T13:29:39.874022Z","iopub.execute_input":"2023-05-29T13:29:39.874430Z","iopub.status.idle":"2023-05-29T13:29:39.889554Z","shell.execute_reply.started":"2023-05-29T13:29:39.874376Z","shell.execute_reply":"2023-05-29T13:29:39.888207Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_excel('/kaggle/working/UIT-VSMEC/train_nor_811.xlsx')\ntest_df = pd.read_excel('/kaggle/working/UIT-VSMEC/test_nor_811.xlsx')\n\ntrain_df = train_df.iloc[:,1:]\ntest_df = test_df.iloc[:,1:]\n\ntrain_df.head()\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T13:29:42.819420Z","iopub.execute_input":"2023-05-29T13:29:42.819874Z","iopub.status.idle":"2023-05-29T13:29:44.780389Z","shell.execute_reply.started":"2023-05-29T13:29:42.819837Z","shell.execute_reply":"2023-05-29T13:29:44.779257Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"    Emotion                                           Sentence\n0   Sadness                   người ta có bạn bè nhìn vui thật\n1  Surprise          cho nghỉ viêc mói đúng sao goi là kỷ luật\n2   Disgust                                         kinh vãi 😡\n3      Fear  nhà thì không xa lắm nhưng chưa bao giờ đi vì ...\n4     Anger      bố không thích nộp đấy mày thích ý kiến không","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emotion</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sadness</td>\n      <td>người ta có bạn bè nhìn vui thật</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Surprise</td>\n      <td>cho nghỉ viêc mói đúng sao goi là kỷ luật</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Disgust</td>\n      <td>kinh vãi 😡</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Fear</td>\n      <td>nhà thì không xa lắm nhưng chưa bao giờ đi vì ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Anger</td>\n      <td>bố không thích nộp đấy mày thích ý kiến không</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T13:29:47.350676Z","iopub.execute_input":"2023-05-29T13:29:47.351570Z","iopub.status.idle":"2023-05-29T13:29:47.365719Z","shell.execute_reply.started":"2023-05-29T13:29:47.351527Z","shell.execute_reply":"2023-05-29T13:29:47.364596Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(5548, 2)\n(693, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"unique_sentiments = train_df.Emotion.unique()\nunique_sentiments","metadata":{"execution":{"iopub.status.busy":"2023-05-29T13:29:49.190463Z","iopub.execute_input":"2023-05-29T13:29:49.190827Z","iopub.status.idle":"2023-05-29T13:29:49.203601Z","shell.execute_reply.started":"2023-05-29T13:29:49.190801Z","shell.execute_reply":"2023-05-29T13:29:49.202186Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array(['Other', 'Disgust', 'Enjoyment', 'Anger', 'Surprise', 'Sadness',\n       'Fear'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"train_df.Emotion.value_counts().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T13:29:51.534669Z","iopub.execute_input":"2023-05-29T13:29:51.535017Z","iopub.status.idle":"2023-05-29T13:29:51.826701Z","shell.execute_reply.started":"2023-05-29T13:29:51.534991Z","shell.execute_reply":"2023-05-29T13:29:51.825771Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot: >"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"test_df.Emotion.value_counts().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T13:29:55.145562Z","iopub.execute_input":"2023-05-29T13:29:55.145927Z","iopub.status.idle":"2023-05-29T13:29:55.401917Z","shell.execute_reply.started":"2023-05-29T13:29:55.145899Z","shell.execute_reply":"2023-05-29T13:29:55.400980Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot: >"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# mapping to the sentiment column \n\ndicto = {'Disgust': 0, 'Enjoyment': 1 , 'Anger': 2, 'Surprise': 3, 'Sadness': 4, 'Fear': 5, 'Other': 6}\n\ntrain_df.Emotion = train_df.Emotion.map(dicto)\ntest_df.Emotion = test_df.Emotion.map(dicto)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T13:29:58.741968Z","iopub.execute_input":"2023-05-29T13:29:58.742402Z","iopub.status.idle":"2023-05-29T13:29:58.754595Z","shell.execute_reply.started":"2023-05-29T13:29:58.742365Z","shell.execute_reply":"2023-05-29T13:29:58.753357Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T15:20:30.515574Z","iopub.execute_input":"2023-05-29T15:20:30.515937Z","iopub.status.idle":"2023-05-29T15:20:30.525301Z","shell.execute_reply.started":"2023-05-29T15:20:30.515908Z","shell.execute_reply":"2023-05-29T15:20:30.524307Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"   Emotion                                           Sentence\n0        4                   người ta có bạn bè nhìn vui thật\n1        3          cho nghỉ viêc mói đúng sao goi là kỷ luật\n2        0                                         kinh vãi 😡\n3        5  nhà thì không xa lắm nhưng chưa bao giờ đi vì ...\n4        2      bố không thích nộp đấy mày thích ý kiến không","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emotion</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>người ta có bạn bè nhìn vui thật</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>cho nghỉ viêc mói đúng sao goi là kỷ luật</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>kinh vãi 😡</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>nhà thì không xa lắm nhưng chưa bao giờ đi vì ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>bố không thích nộp đấy mày thích ý kiến không</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def classical_model(train_df, test_df , bow=False, TFIDF=False, Ngram=False,\n                    model=linear_model.LogisticRegression(solver='liblinear')):\n    '''\n    Automates classical models to train and evaluate Sentiment Analysis Models.\n\n    Args:\n    train_df, test_df : pandas DataFrame\n        DataFrame with columns Sentence and Emotion\n    bow : bool\n        Flag for using bag of words (binary, count, or frequency)\n    TFIDF : bool\n        Flag for using Tfidf vectorization\n    Ngram : tuple\n        Shape of Ngram range (e.g. (1,2) for bigrams)\n    model : scikit-learn estimator\n        Model to be used for training\n\n    Returns:\n    None\n    '''\n\n\n    # Initiate kfold class from model_selection module\n    np.random.seed(0)\n\n\n    if bow:\n        count_vec = CountVectorizer(tokenizer=word_tokenize, token_pattern=None)\n    elif TFIDF:\n        count_vec = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)\n    elif Ngram:\n        count_vec = CountVectorizer(tokenizer=word_tokenize, token_pattern=None, ngram_range=Ngram)\n\n    count_vec.fit(train_df.Sentence)\n    xtrain = count_vec.transform(train_df.Sentence)\n    xtest = count_vec.transform(test_df.Sentence)\n    model.fit(xtrain, train_df.Emotion)\n    preds = model.predict(xtest)\n    accuracy_precision = precision_score(test_df.Emotion, preds, average='macro')\n    accuracy_recall = recall_score(test_df.Emotion, preds, average='macro')\n    print('precision score:', accuracy_precision)\n    print('recall score:', accuracy_recall)\n    print(\"========================================================\")\n\n    print(classification_report(test_df.Emotion, preds))","metadata":{"execution":{"iopub.status.busy":"2023-05-29T15:20:41.432521Z","iopub.execute_input":"2023-05-29T15:20:41.432878Z","iopub.status.idle":"2023-05-29T15:20:41.445787Z","shell.execute_reply.started":"2023-05-29T15:20:41.432851Z","shell.execute_reply":"2023-05-29T15:20:41.444500Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Model 1 : Logistic + BOW","metadata":{}},{"cell_type":"code","source":"#Baseline model let's start with a logistic regression model since it is the fastest for high dimensional sparse data\n\nclassical_model(train_df, test_df , bow =True,model=linear_model.LogisticRegression(solver = 'liblinear'))","metadata":{"execution":{"iopub.status.busy":"2023-05-29T15:20:44.073370Z","iopub.execute_input":"2023-05-29T15:20:44.074245Z","iopub.status.idle":"2023-05-29T15:20:47.160955Z","shell.execute_reply.started":"2023-05-29T15:20:44.074210Z","shell.execute_reply":"2023-05-29T15:20:47.159948Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"precision score: 0.5815327032247299\nrecall score: 0.49640963700261315\n========================================================\n              precision    recall  f1-score   support\n\n           0       0.51      0.52      0.51       132\n           1       0.61      0.72      0.66       193\n           2       0.36      0.25      0.29        40\n           3       0.71      0.27      0.39        37\n           4       0.63      0.59      0.61       116\n           5       0.77      0.59      0.67        46\n           6       0.48      0.54      0.51       129\n\n    accuracy                           0.57       693\n   macro avg       0.58      0.50      0.52       693\nweighted avg       0.57      0.57      0.56       693\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model 2 : NaiveBayes + BOW","metadata":{}},{"cell_type":"code","source":"# Lets try with NaiveBayes model \n\nclassical_model(train_df, test_df ,bow = True,model = MultinomialNB()) # multiclassification","metadata":{"execution":{"iopub.status.busy":"2023-05-29T15:20:50.144794Z","iopub.execute_input":"2023-05-29T15:20:50.145150Z","iopub.status.idle":"2023-05-29T15:20:52.659785Z","shell.execute_reply.started":"2023-05-29T15:20:50.145123Z","shell.execute_reply":"2023-05-29T15:20:52.658609Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"precision score: 0.5469550809353907\nrecall score: 0.42595634353686523\n========================================================\n              precision    recall  f1-score   support\n\n           0       0.44      0.61      0.51       132\n           1       0.55      0.69      0.62       193\n           2       0.43      0.25      0.32        40\n           3       0.60      0.08      0.14        37\n           4       0.61      0.58      0.60       116\n           5       0.71      0.37      0.49        46\n           6       0.47      0.40      0.44       129\n\n    accuracy                           0.52       693\n   macro avg       0.55      0.43      0.44       693\nweighted avg       0.53      0.52      0.51       693\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model 3 : Naive Bayes with TFIDF\n","metadata":{}},{"cell_type":"code","source":"# Now lets try with TF-IDF vectorizer instead of bag of words to MultinomialNB().\n\nclassical_model(train_df, test_df, model= MultinomialNB(),TFIDF=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T15:20:56.289783Z","iopub.execute_input":"2023-05-29T15:20:56.290182Z","iopub.status.idle":"2023-05-29T15:20:58.775288Z","shell.execute_reply.started":"2023-05-29T15:20:56.290125Z","shell.execute_reply":"2023-05-29T15:20:58.774329Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"precision score: 0.3107018415761585\nrecall score: 0.3052240704159713\n========================================================\n              precision    recall  f1-score   support\n\n           0       0.48      0.54      0.51       132\n           1       0.42      0.89      0.58       193\n           2       0.00      0.00      0.00        40\n           3       0.00      0.00      0.00        37\n           4       0.77      0.41      0.53       116\n           5       0.00      0.00      0.00        46\n           6       0.50      0.30      0.38       129\n\n    accuracy                           0.47       693\n   macro avg       0.31      0.31      0.28       693\nweighted avg       0.43      0.47      0.42       693\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model 4 : Naive Bayes with Ngrams\n","metadata":{}},{"cell_type":"code","source":"# Now to the baseline bag of word Naivebayes model lets apply Ngrams  and compare the results.\n\n# Lets try with NaiveBayes model \n\nclassical_model(train_df, test_df, model = MultinomialNB(), Ngram=(1,2))","metadata":{"execution":{"iopub.status.busy":"2023-05-29T15:20:58.777401Z","iopub.execute_input":"2023-05-29T15:20:58.778126Z","iopub.status.idle":"2023-05-29T15:21:02.241877Z","shell.execute_reply.started":"2023-05-29T15:20:58.778089Z","shell.execute_reply":"2023-05-29T15:21:02.240877Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"precision score: 0.5274402784369562\nrecall score: 0.3516363282101255\n========================================================\n              precision    recall  f1-score   support\n\n           0       0.38      0.64      0.48       132\n           1       0.52      0.81      0.63       193\n           2       0.75      0.07      0.14        40\n           3       0.00      0.00      0.00        37\n           4       0.62      0.48      0.54       116\n           5       0.90      0.20      0.32        46\n           6       0.52      0.26      0.34       129\n\n    accuracy                           0.49       693\n   macro avg       0.53      0.35      0.35       693\nweighted avg       0.52      0.49      0.45       693\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"code","source":"def create_stopwordlist():\n    f = codecs.open('/kaggle/input/vietnamese-stopwords/vietnamese-stopwords.txt', encoding='utf-8')\n    data = []\n    null_data = []\n    for i, line in enumerate(f):\n        line = repr(line)\n        line = line[1:len(line)-3]\n        data.append(line)\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-05-29T15:21:30.977512Z","iopub.execute_input":"2023-05-29T15:21:30.978211Z","iopub.status.idle":"2023-05-29T15:21:30.986886Z","shell.execute_reply.started":"2023-05-29T15:21:30.978171Z","shell.execute_reply":"2023-05-29T15:21:30.985881Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"stopword_vn = create_stopwordlist()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T15:21:33.463794Z","iopub.execute_input":"2023-05-29T15:21:33.464144Z","iopub.status.idle":"2023-05-29T15:21:33.491727Z","shell.execute_reply.started":"2023-05-29T15:21:33.464117Z","shell.execute_reply":"2023-05-29T15:21:33.490802Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import string\n\ndef tokenize(text):\n    #text =  text.translate(str.maketrans('', '', string.punctuation))\n    return [word for word in word_tokenize(text.lower()) if word not in stopword_vn]","metadata":{"execution":{"iopub.status.busy":"2023-05-29T15:21:36.648762Z","iopub.execute_input":"2023-05-29T15:21:36.649353Z","iopub.status.idle":"2023-05-29T15:21:36.659781Z","shell.execute_reply.started":"2023-05-29T15:21:36.649312Z","shell.execute_reply":"2023-05-29T15:21:36.658752Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def new_classical_model(train_df, test_df , option='generate', bow=False, TFIDF=False, Ngram=False,\n                    model=linear_model.LogisticRegression(solver='liblinear')):\n    '''\n    Automates classical models to train and evaluate Sentiment Analysis Models.\n\n    Args:\n    train_df, test_df : pandas DataFrame\n        DataFrame with columns Sentence and Emotion\n    bow : bool\n        Flag for using bag of words (binary, count, or frequency)\n    TFIDF : bool\n        Flag for using Tfidf vectorization\n    Ngram : tuple\n        Shape of Ngram range (e.g. (1,2) for bigrams)\n    model : scikit-learn estimator\n        Model to be used for training\n\n    Returns:\n    None\n    '''\n\n    # Initiate kfold class from model_selection module\n    np.random.seed(0)\n\n    if option == 'generate':\n        if bow:\n            vectorizer = CountVectorizer(tokenizer = tokenize, token_pattern=None)\n        elif TFIDF:\n            vectorizer = TfidfVectorizer(tokenizer = tokenize, token_pattern=None)\n        elif Ngram:\n            vectorizer = CountVectorizer(tokenizer = tokenize, ngram_range=Ngram, token_pattern=None)\n    elif option == 'load':\n        if bow:\n            vectorizer = CountVectorizer(vocabulary = pickle.load(open('../input/kpdl-data/vocabulary_2.pkl', 'rb')), ngram_range=(1,3), max_df=0.8, min_df=5, max_features = 15000)\n        elif TFIDF:\n            vectorizer = TfidfVectorizer(vocabulary = pickle.load(open('../input/kpdl-data/vocabulary_2.pkl', 'rb')), ngram_range=(1,3), min_df=5, max_df= 0.8, max_features=15000)\n\n    vectorizer.fit(train_df.Sentence)\n    xtrain = vectorizer.transform(train_df.Sentence)\n    xtest = vectorizer.transform(test_df.Sentence)\n    model.fit(xtrain, train_df.Emotion)\n    preds = model.predict(xtest)\n    accuracy_precision = precision_score(test_df.Emotion, preds, average='macro')\n    accuracy_recall = recall_score(test_df.Emotion, preds, average='macro')\n    print('precision score:', accuracy_precision)\n    print('recall score:', accuracy_recall)\n    print(\"========================================================\")\n\n    print(classification_report(test_df.Emotion, preds))","metadata":{"execution":{"iopub.status.busy":"2023-05-29T15:21:39.002290Z","iopub.execute_input":"2023-05-29T15:21:39.003261Z","iopub.status.idle":"2023-05-29T15:21:39.015775Z","shell.execute_reply.started":"2023-05-29T15:21:39.003214Z","shell.execute_reply":"2023-05-29T15:21:39.014716Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Model 5 : cleaned text Naive Bayes + BOW","metadata":{}},{"cell_type":"code","source":"#Now lets try this on our baseline MultinomialNB bagofwords model\n\nnew_classical_model(train_df, test_df, model = MultinomialNB(),bow = True)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T12:19:53.711990Z","iopub.execute_input":"2023-05-22T12:19:53.712806Z","iopub.status.idle":"2023-05-22T12:19:59.332995Z","shell.execute_reply.started":"2023-05-22T12:19:53.712768Z","shell.execute_reply":"2023-05-22T12:19:59.331907Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"precision score: 0.5749853609972477\nrecall score: 0.38763365091499224\n========================================================\n              precision    recall  f1-score   support\n\n       Anger       0.36      0.23      0.28        40\n     Disgust       0.42      0.58      0.49       132\n   Enjoyment       0.51      0.72      0.59       193\n        Fear       0.64      0.35      0.45        46\n       Other       0.41      0.34      0.37       129\n     Sadness       0.69      0.47      0.56       116\n    Surprise       1.00      0.03      0.05        37\n\n    accuracy                           0.49       693\n   macro avg       0.57      0.39      0.40       693\nweighted avg       0.53      0.49      0.47       693\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model 6 : Fastext vector with Naive Bayes Baseline","metadata":{}},{"cell_type":"markdown","source":"# Train FastText","metadata":{}},{"cell_type":"code","source":"merge_df = pd.concat([train_df, test_df], ignore_index=True)\nx_tokenized = []\n\nfor sentence in merge_df['Sentence'].values:\n    tokens = [word for word in word_tokenize(sentence.lower()) if word not in stopword_vn]\n    x_tokenized.append(tokens)\n    \nmodel = gensim.models.FastText(sentences=x_tokenized, vector_size=300, window=3, min_count=5, workers=4)    \n\n#model.save('/kaggle/working/fasttext_model.bin')","metadata":{"execution":{"iopub.status.busy":"2023-05-22T12:37:48.308737Z","iopub.execute_input":"2023-05-22T12:37:48.309479Z","iopub.status.idle":"2023-05-22T12:38:02.529949Z","shell.execute_reply.started":"2023-05-22T12:37:48.309440Z","shell.execute_reply":"2023-05-22T12:38:02.528910Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"merge_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In this model we will use fastText vectors and also convert each word vector in sentence vector.\n# The code is taken from https://fasttext.cc/docs/en/english-vectors.html, this code splits each vector by \n# space and return for more info go through the above link.\n\ndef sentence_to_vec(sentence, embedding_dict, tokenizer):\n    # This function converts a sentence to a vector of word vectors\n    words = tokenizer(sentence)\n    embedding_list = []\n    for word in words:\n        if word in embedding_dict:\n            embedding_list.append(embedding_dict[word])\n    if len(embedding_list) == 0:\n        # if no vectors are found, return zeros\n        return np.zeros(300)\n    embedding_list = np.array(embedding_list)\n    vector = embedding_list.sum(axis=0) / len(embedding_list)\n    return vector","metadata":{"execution":{"iopub.status.busy":"2023-05-29T15:22:12.979091Z","iopub.execute_input":"2023-05-29T15:22:12.979535Z","iopub.status.idle":"2023-05-29T15:22:12.988669Z","shell.execute_reply.started":"2023-05-29T15:22:12.979503Z","shell.execute_reply":"2023-05-29T15:22:12.987653Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"ft_model  = gensim.models.FastText.load('/kaggle/working/fasttext_model.bin')","metadata":{"execution":{"iopub.status.busy":"2023-05-22T12:38:19.608540Z","iopub.execute_input":"2023-05-22T12:38:19.608931Z","iopub.status.idle":"2023-05-22T12:38:22.061302Z","shell.execute_reply.started":"2023-05-22T12:38:19.608900Z","shell.execute_reply":"2023-05-22T12:38:22.060334Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"!gdown https://thiaisotajppub.s3-ap-northeast-1.amazonaws.com/publicfiles/baomoi.model.bin","metadata":{"execution":{"iopub.status.busy":"2023-05-29T15:22:23.532879Z","iopub.execute_input":"2023-05-29T15:22:23.533380Z","iopub.status.idle":"2023-05-29T15:23:19.519671Z","shell.execute_reply.started":"2023-05-29T15:22:23.533346Z","shell.execute_reply":"2023-05-29T15:23:19.518447Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://thiaisotajppub.s3-ap-northeast-1.amazonaws.com/publicfiles/baomoi.model.bin\nTo: /kaggle/working/baomoi.model.bin\n100%|████████████████████████████████████████| 708M/708M [00:53<00:00, 13.2MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load embeddings into memory\n# print(\"Loading embeddings\")\nembeddings_vi = KeyedVectors.load_word2vec_format('/kaggle/input/kpdl-data/baomoi.model.bin', binary=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T15:26:38.691841Z","iopub.execute_input":"2023-05-29T15:26:38.692199Z","iopub.status.idle":"2023-05-29T15:26:49.870924Z","shell.execute_reply.started":"2023-05-29T15:26:38.692171Z","shell.execute_reply":"2023-05-29T15:26:49.869869Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Create sentence embeddings\nprint(\"Creating sentence vectors\")\nvectors_train = []\nvectors_test = []\nfor sentence in train_df['Sentence'].values:\n    vectors_train.append(sentence_to_vec(sentence=sentence, embedding_dict=embeddings_vi, tokenizer=ViTokenizer.tokenize))\n    #vectors_train.append(ft_model.wv.get_sentence_vector(sentence))\nfor sentence in test_df['Sentence'].values:\n    vectors_test.append(sentence_to_vec(sentence=sentence, embedding_dict=embeddings_vi, tokenizer=ViTokenizer.tokenize))\n    #vectors_test.append(ft_model.wv.get_sentence_vector(sentence))\n\nvectors_train = np.array(vectors_train)\nvectors_test = np.array(vectors_test)\n\n\nx_train = vectors_train\ny_train = train_df['Emotion'].values\nx_test = vectors_test\ny_test = test_df['Emotion'].values\n\n\nscaler = MinMaxScaler()\nx_train_scaled = scaler.fit_transform(x_train)\nx_test_scaled = scaler.transform(x_test)\n\nmodel = MultinomialNB()\nmodel.fit(x_train_scaled, y_train)\ny_pred = model.predict(x_test_scaled)\npres_score = precision_score(y_test, y_pred, average='macro')\nrec_score = recall_score(y_test, y_pred, average='macro')\nprint('Precision and recall scores:', pres_score, rec_score)\nprint(\"======================================================\")\nprint(classification_report(y_test, y_pred, labels=[0, 1, 2, 3, 4, 5, 6]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scoring(y_train,y_pred):\n    return f1_score(y_train,y_pred,average='macro')\n\ncount_vec = CountVectorizer(tokenizer = word_tokenize, token_pattern = None)\n\nX_train = count_vec.fit_transform(train_df.Sentence)\n\nparameters = {'alpha': [0.001,0.01,0.1,0.2,0.3,0.5,0.7,1,1.5,1.6,1.8,10,100]}\n\nmodel = MultinomialNB()\n\ngrid_search = GridSearchCV(model , parameters, cv=5, scoring = make_scorer(scoring), n_jobs = -1, verbose= 1)\n\ngrid_result = grid_search.fit(X_train, train_df.Emotion)\n\nprint('Best params: ', grid_result.best_params_)\nprint('Best score: ', grid_result.best_score_)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:05:34.132887Z","iopub.execute_input":"2023-05-22T13:05:34.133267Z","iopub.status.idle":"2023-05-22T13:05:38.323553Z","shell.execute_reply.started":"2023-05-22T13:05:34.133236Z","shell.execute_reply":"2023-05-22T13:05:38.322304Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 13 candidates, totalling 65 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Best params:  {'alpha': 0.2}\nBest score:  0.4792960700623011\n","output_type":"stream"}]},{"cell_type":"code","source":"# Lets also check svm hyperparameters using pipelines\n\nmerge_df = merge_df.sample(frac=1,random_state=42).reset_index(drop=True)\n\n\n\ncount_vec = CountVectorizer(tokenizer = word_tokenize, token_pattern = None)\n\nX_train = count_vec.fit_transform(merge_df.Sentence)\n\n# defining parameter range\nparam_grid = {'C': [0.1, 1, 10, 100],\n              'gamma': [1, 0.1, 0.01, 0.001],\n              'kernel': ['rbf','linear']}\n \ngrid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 1, cv=5, scoring = make_scorer(scoring), n_jobs = -1)\n \n# fitting the model for grid search\ngrid.fit(X_train, merge_df.Emotion)\n\nprint('Best params: ', grid.best_params_)\nprint('Best score: ', grid.best_score_)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:08:14.175870Z","iopub.execute_input":"2023-05-22T13:08:14.176993Z","iopub.status.idle":"2023-05-22T13:20:00.417456Z","shell.execute_reply.started":"2023-05-22T13:08:14.176945Z","shell.execute_reply":"2023-05-22T13:20:00.416391Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 32 candidates, totalling 160 fits\nBest params:  {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\nBest score:  0.516251685847836\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Classify text with BERT ( Transfer Learning )","metadata":{}},{"cell_type":"code","source":"# Load the pre-trained BERT model and tokenizer\nmodel_name = 'bert-base-uncased'\ntokenizer = BertTokenizer.from_pretrained(model_name)\nbert_model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=7)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:15:00.616451Z","iopub.execute_input":"2023-05-22T15:15:00.616928Z","iopub.status.idle":"2023-05-22T15:15:02.381442Z","shell.execute_reply.started":"2023-05-22T15:15:00.616891Z","shell.execute_reply":"2023-05-22T15:15:02.379940Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stderr","text":"All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n\nSome layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"bert_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:15:04.232687Z","iopub.execute_input":"2023-05-22T15:15:04.233306Z","iopub.status.idle":"2023-05-22T15:15:04.276872Z","shell.execute_reply.started":"2023-05-22T15:15:04.233261Z","shell.execute_reply":"2023-05-22T15:15:04.275793Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"Model: \"tf_bert_for_sequence_classification_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n bert (TFBertMainLayer)      multiple                  109482240 \n                                                                 \n dropout_188 (Dropout)       multiple                  0         \n                                                                 \n classifier (Dense)          multiple                  5383      \n                                                                 \n=================================================================\nTotal params: 109,487,623\nTrainable params: 109,487,623\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the optimizer, loss function, and metrics\noptimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)\nloss = tf.keras.losses.CategoricalCrossentropy()\nmetrics = [tf.keras.metrics.CategoricalAccuracy()]","metadata":{"execution":{"iopub.status.busy":"2023-05-22T16:32:40.638444Z","iopub.execute_input":"2023-05-22T16:32:40.638904Z","iopub.status.idle":"2023-05-22T16:32:40.651044Z","shell.execute_reply.started":"2023-05-22T16:32:40.638861Z","shell.execute_reply":"2023-05-22T16:32:40.650121Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"# Define the model inputs and outputs\ninput_ids = tf.keras.layers.Input(shape=(98,), dtype=tf.int32, name='input_ids')\nattention_mask = tf.keras.layers.Input(shape=(98,), dtype=tf.int32, name='attention_mask')\noutput = bert_model({'input_ids': input_ids, 'attention_mask': attention_mask})[0]\n\n# Add a dense layer with softmax activation for classification\noutput = tf.keras.layers.Dense(7, activation='softmax')(output)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T16:32:43.749124Z","iopub.execute_input":"2023-05-22T16:32:43.749514Z","iopub.status.idle":"2023-05-22T16:32:45.653109Z","shell.execute_reply.started":"2023-05-22T16:32:43.749481Z","shell.execute_reply":"2023-05-22T16:32:45.652125Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"# Define the model\nmodel = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=output)\n\n# Compile the model\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T16:32:48.883419Z","iopub.execute_input":"2023-05-22T16:32:48.883892Z","iopub.status.idle":"2023-05-22T16:32:48.908615Z","shell.execute_reply.started":"2023-05-22T16:32:48.883828Z","shell.execute_reply":"2023-05-22T16:32:48.907475Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T16:32:53.831509Z","iopub.execute_input":"2023-05-22T16:32:53.831982Z","iopub.status.idle":"2023-05-22T16:32:53.916075Z","shell.execute_reply.started":"2023-05-22T16:32:53.831942Z","shell.execute_reply":"2023-05-22T16:32:53.915132Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stdout","text":"Model: \"model_6\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n attention_mask (InputLayer)    [(None, 98)]         0           []                               \n                                                                                                  \n input_ids (InputLayer)         [(None, 98)]         0           []                               \n                                                                                                  \n tf_bert_for_sequence_classific  TFSequenceClassifie  109487623  ['attention_mask[0][0]',         \n ation_3 (TFBertForSequenceClas  rOutput(loss=None,               'input_ids[0][0]']              \n sification)                    logits=(None, 7),                                                 \n                                 hidden_states=None                                               \n                                , attentions=None)                                                \n                                                                                                  \n dense_7 (Dense)                (None, 7)            56          ['tf_bert_for_sequence_classifica\n                                                                 tion_3[2][0]']                   \n                                                                                                  \n==================================================================================================\nTotal params: 109,487,679\nTrainable params: 109,487,679\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the training and validation datasets\n\ndef datasets(tokenizer):\n    \n    # Split the data into training and validation sets\n#     train_df, val_df, train_labels, val_labels = train_test_split(df.Sentence, df.Sentiment,\n#                                                                   test_size=0.2, random_state=42,stratify = df.Sentiment)\n    train = train_df.Sentence\n    train_labels = train_df.Emotion.values\n    #print(train_labels)\n    val_df = test_df.Sentence\n    val_labels = test_df.Emotion.values\n    # Tokenize the input sequences and convert to input IDs and attention masks\n    train_encodings = tokenizer(list(train.values), truncation=True, padding=True,max_length=98)\n    train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=7)\n    train_dataset = tf.data.Dataset.from_tensor_slices(({'input_ids': train_encodings['input_ids'], 'attention_mask': train_encodings['attention_mask']}, train_labels))\n    \n    val_encodings = tokenizer(list(val_df.values), truncation=True, padding=True,max_length=98)\n    val_labels = tf.keras.utils.to_categorical(val_labels, num_classes=7)\n    val_dataset = tf.data.Dataset.from_tensor_slices(({'input_ids': val_encodings['input_ids'], 'attention_mask': val_encodings['attention_mask']}, val_labels))\n    \n    \n    # Batch and shuffle the datasets\n    batch_size = 32\n    train_dataset = train_dataset.batch(batch_size).shuffle(1000)\n    val_dataset = val_dataset.batch(batch_size)\n    \n    return train_dataset,val_dataset","metadata":{"execution":{"iopub.status.busy":"2023-05-23T02:43:26.165935Z","iopub.execute_input":"2023-05-23T02:43:26.166693Z","iopub.status.idle":"2023-05-23T02:43:26.178119Z","shell.execute_reply.started":"2023-05-23T02:43:26.166655Z","shell.execute_reply":"2023-05-23T02:43:26.177064Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Define the training and validation datasets\n\ntrain_dataset,val_dataset = datasets(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T16:33:02.283336Z","iopub.execute_input":"2023-05-22T16:33:02.283723Z","iopub.status.idle":"2023-05-22T16:33:10.602598Z","shell.execute_reply.started":"2023-05-22T16:33:02.283689Z","shell.execute_reply":"2023-05-22T16:33:10.601565Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"# Train the model for a few epochs\nnum_epochs = 20\nmodel.fit(train_dataset, validation_data=val_dataset, epochs=num_epochs)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T16:33:10.604845Z","iopub.execute_input":"2023-05-22T16:33:10.605248Z","iopub.status.idle":"2023-05-22T17:13:11.763396Z","shell.execute_reply.started":"2023-05-22T16:33:10.605213Z","shell.execute_reply":"2023-05-22T17:13:11.762403Z"},"trusted":true},"execution_count":128,"outputs":[{"name":"stdout","text":"Epoch 1/20\n174/174 [==============================] - 159s 650ms/step - loss: 1.0212 - categorical_accuracy: 0.6885 - val_loss: 2.1200 - val_categorical_accuracy: 0.4719\nEpoch 2/20\n174/174 [==============================] - 109s 628ms/step - loss: 0.4043 - categorical_accuracy: 0.8805 - val_loss: 2.0397 - val_categorical_accuracy: 0.4877\nEpoch 3/20\n174/174 [==============================] - 109s 629ms/step - loss: 0.2708 - categorical_accuracy: 0.9193 - val_loss: 2.0994 - val_categorical_accuracy: 0.4935\nEpoch 4/20\n174/174 [==============================] - 109s 628ms/step - loss: 0.1929 - categorical_accuracy: 0.9439 - val_loss: 2.4048 - val_categorical_accuracy: 0.4719\nEpoch 5/20\n174/174 [==============================] - 110s 632ms/step - loss: 0.1810 - categorical_accuracy: 0.9445 - val_loss: 2.3505 - val_categorical_accuracy: 0.4618\nEpoch 6/20\n174/174 [==============================] - 109s 629ms/step - loss: 0.1286 - categorical_accuracy: 0.9618 - val_loss: 2.6015 - val_categorical_accuracy: 0.4892\nEpoch 7/20\n174/174 [==============================] - 109s 629ms/step - loss: 0.1113 - categorical_accuracy: 0.9672 - val_loss: 2.5766 - val_categorical_accuracy: 0.4762\nEpoch 8/20\n174/174 [==============================] - 109s 629ms/step - loss: 0.1270 - categorical_accuracy: 0.9612 - val_loss: 2.5435 - val_categorical_accuracy: 0.4906\nEpoch 9/20\n174/174 [==============================] - 110s 631ms/step - loss: 0.0919 - categorical_accuracy: 0.9695 - val_loss: 2.7817 - val_categorical_accuracy: 0.4921\nEpoch 10/20\n174/174 [==============================] - 109s 628ms/step - loss: 0.1043 - categorical_accuracy: 0.9710 - val_loss: 2.6132 - val_categorical_accuracy: 0.4964\nEpoch 11/20\n174/174 [==============================] - 109s 628ms/step - loss: 0.1097 - categorical_accuracy: 0.9643 - val_loss: 2.6894 - val_categorical_accuracy: 0.5036\nEpoch 12/20\n174/174 [==============================] - 109s 628ms/step - loss: 0.0873 - categorical_accuracy: 0.9717 - val_loss: 2.8708 - val_categorical_accuracy: 0.4949\nEpoch 13/20\n174/174 [==============================] - 110s 631ms/step - loss: 0.0779 - categorical_accuracy: 0.9766 - val_loss: 2.7983 - val_categorical_accuracy: 0.5022\nEpoch 14/20\n174/174 [==============================] - 109s 628ms/step - loss: 0.0946 - categorical_accuracy: 0.9744 - val_loss: 2.7419 - val_categorical_accuracy: 0.5022\nEpoch 15/20\n174/174 [==============================] - 110s 630ms/step - loss: 0.0575 - categorical_accuracy: 0.9829 - val_loss: 2.9266 - val_categorical_accuracy: 0.4603\nEpoch 16/20\n174/174 [==============================] - 110s 630ms/step - loss: 0.0621 - categorical_accuracy: 0.9813 - val_loss: 3.0082 - val_categorical_accuracy: 0.4877\nEpoch 17/20\n174/174 [==============================] - 110s 630ms/step - loss: 0.0558 - categorical_accuracy: 0.9840 - val_loss: 2.8963 - val_categorical_accuracy: 0.5108\nEpoch 18/20\n174/174 [==============================] - 109s 628ms/step - loss: 0.0560 - categorical_accuracy: 0.9834 - val_loss: 2.9845 - val_categorical_accuracy: 0.4906\nEpoch 19/20\n174/174 [==============================] - 110s 630ms/step - loss: 0.0535 - categorical_accuracy: 0.9834 - val_loss: 3.1696 - val_categorical_accuracy: 0.4690\nEpoch 20/20\n174/174 [==============================] - 109s 627ms/step - loss: 0.0608 - categorical_accuracy: 0.9811 - val_loss: 3.2871 - val_categorical_accuracy: 0.4646\n","output_type":"stream"},{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7c2f082d4820>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Classify text with RoBERTa ( Transfer Learning )","metadata":{}},{"cell_type":"code","source":"# Load the RoBERTa tokenizer and model\nroberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\nroberta_model = TFRobertaModel.from_pretrained('roberta-base')","metadata":{"execution":{"iopub.status.busy":"2023-05-22T17:13:11.765434Z","iopub.execute_input":"2023-05-22T17:13:11.765935Z","iopub.status.idle":"2023-05-22T17:13:13.894607Z","shell.execute_reply.started":"2023-05-22T17:13:11.765890Z","shell.execute_reply":"2023-05-22T17:13:13.893515Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stderr","text":"Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the training and validation datasets\n\ntrain_dataset,val_dataset = datasets(roberta_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T17:13:13.896704Z","iopub.execute_input":"2023-05-22T17:13:13.897673Z","iopub.status.idle":"2023-05-22T17:13:19.642332Z","shell.execute_reply.started":"2023-05-22T17:13:13.897635Z","shell.execute_reply":"2023-05-22T17:13:19.641261Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"# Define the input shape for the model\nmax_length = 98\n\n# Define the custom top layer for classification\nnum_labels = 7\ntop_layer = tf.keras.layers.Dense(num_labels, activation='softmax')\n\n# Define the RoBERTa model with the custom top layer\ninput_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='input_ids')\nattention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='attention_mask')\nroberta_output = roberta_model({'input_ids': input_ids, 'attention_mask': attention_mask})\nroberta_output = roberta_output.last_hidden_state[:, 0, :]\nroberta_output = top_layer(roberta_output)\nroberta_model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=[roberta_output])\n\nprint(roberta_model.summary())\n\n# Define the loss function and metrics for training\nloss = tf.keras.losses.CategoricalCrossentropy()\nmetrics = [tf.keras.metrics.CategoricalAccuracy()]\noptimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n\n# Compile the RoBERTa model for training\nroberta_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n\n# Train the RoBERTa model on the sentiment analysis task\nroberta_model.fit(train_dataset, epochs=20, validation_data=val_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T17:13:19.645485Z","iopub.execute_input":"2023-05-22T17:13:19.645916Z","iopub.status.idle":"2023-05-22T17:52:19.850743Z","shell.execute_reply.started":"2023-05-22T17:13:19.645878Z","shell.execute_reply":"2023-05-22T17:52:19.849759Z"},"trusted":true},"execution_count":131,"outputs":[{"name":"stdout","text":"Model: \"model_7\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n attention_mask (InputLayer)    [(None, 98)]         0           []                               \n                                                                                                  \n input_ids (InputLayer)         [(None, 98)]         0           []                               \n                                                                                                  \n tf_roberta_model_1 (TFRobertaM  TFBaseModelOutputWi  124645632  ['attention_mask[0][0]',         \n odel)                          thPoolingAndCrossAt               'input_ids[0][0]']              \n                                tentions(last_hidde                                               \n                                n_state=(None, 98,                                                \n                                768),                                                             \n                                 pooler_output=(Non                                               \n                                e, 768),                                                          \n                                 past_key_values=No                                               \n                                ne, hidden_states=N                                               \n                                one, attentions=Non                                               \n                                e, cross_attentions                                               \n                                =None)                                                            \n                                                                                                  \n tf.__operators__.getitem_2 (Sl  (None, 768)         0           ['tf_roberta_model_1[0][0]']     \n icingOpLambda)                                                                                   \n                                                                                                  \n dense_8 (Dense)                (None, 7)            5383        ['tf.__operators__.getitem_2[0][0\n                                                                 ]']                              \n                                                                                                  \n==================================================================================================\nTotal params: 124,651,015\nTrainable params: 124,651,015\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nEpoch 1/20\n174/174 [==============================] - 159s 665ms/step - loss: 1.7383 - categorical_accuracy: 0.3154 - val_loss: 1.6475 - val_categorical_accuracy: 0.3853\nEpoch 2/20\n174/174 [==============================] - 111s 640ms/step - loss: 1.5919 - categorical_accuracy: 0.3983 - val_loss: 1.5487 - val_categorical_accuracy: 0.4141\nEpoch 3/20\n174/174 [==============================] - 112s 644ms/step - loss: 1.4853 - categorical_accuracy: 0.4477 - val_loss: 1.5147 - val_categorical_accuracy: 0.4271\nEpoch 4/20\n174/174 [==============================] - 111s 640ms/step - loss: 1.3667 - categorical_accuracy: 0.4858 - val_loss: 1.3740 - val_categorical_accuracy: 0.4848\nEpoch 5/20\n174/174 [==============================] - 111s 639ms/step - loss: 1.2429 - categorical_accuracy: 0.5461 - val_loss: 1.4197 - val_categorical_accuracy: 0.4805\nEpoch 6/20\n174/174 [==============================] - 112s 642ms/step - loss: 1.1279 - categorical_accuracy: 0.5903 - val_loss: 1.4579 - val_categorical_accuracy: 0.4675\nEpoch 7/20\n174/174 [==============================] - 111s 641ms/step - loss: 1.0085 - categorical_accuracy: 0.6348 - val_loss: 1.5969 - val_categorical_accuracy: 0.4993\nEpoch 8/20\n174/174 [==============================] - 111s 640ms/step - loss: 0.9188 - categorical_accuracy: 0.6572 - val_loss: 1.6421 - val_categorical_accuracy: 0.4805\nEpoch 9/20\n174/174 [==============================] - 111s 640ms/step - loss: 0.8129 - categorical_accuracy: 0.7021 - val_loss: 1.6855 - val_categorical_accuracy: 0.5079\nEpoch 10/20\n174/174 [==============================] - 112s 644ms/step - loss: 0.7122 - categorical_accuracy: 0.7435 - val_loss: 1.8446 - val_categorical_accuracy: 0.5051\nEpoch 11/20\n174/174 [==============================] - 111s 640ms/step - loss: 0.6195 - categorical_accuracy: 0.7797 - val_loss: 1.8533 - val_categorical_accuracy: 0.5036\nEpoch 12/20\n174/174 [==============================] - 112s 644ms/step - loss: 0.5112 - categorical_accuracy: 0.8142 - val_loss: 2.0021 - val_categorical_accuracy: 0.4921\nEpoch 13/20\n174/174 [==============================] - 111s 641ms/step - loss: 0.6785 - categorical_accuracy: 0.7549 - val_loss: 1.9581 - val_categorical_accuracy: 0.4935\nEpoch 14/20\n174/174 [==============================] - 111s 639ms/step - loss: 0.5388 - categorical_accuracy: 0.8075 - val_loss: 2.1526 - val_categorical_accuracy: 0.4921\nEpoch 15/20\n174/174 [==============================] - 111s 640ms/step - loss: 0.3676 - categorical_accuracy: 0.8663 - val_loss: 2.2820 - val_categorical_accuracy: 0.4863\nEpoch 16/20\n174/174 [==============================] - 111s 639ms/step - loss: 0.3043 - categorical_accuracy: 0.8929 - val_loss: 2.5426 - val_categorical_accuracy: 0.4791\nEpoch 17/20\n174/174 [==============================] - 111s 641ms/step - loss: 0.2503 - categorical_accuracy: 0.9142 - val_loss: 2.7631 - val_categorical_accuracy: 0.4848\nEpoch 18/20\n174/174 [==============================] - 112s 644ms/step - loss: 0.2021 - categorical_accuracy: 0.9302 - val_loss: 2.9583 - val_categorical_accuracy: 0.4820\nEpoch 19/20\n174/174 [==============================] - 111s 639ms/step - loss: 0.1957 - categorical_accuracy: 0.9313 - val_loss: 3.0285 - val_categorical_accuracy: 0.4949\nEpoch 20/20\n174/174 [==============================] - 111s 641ms/step - loss: 0.1788 - categorical_accuracy: 0.9389 - val_loss: 3.2005 - val_categorical_accuracy: 0.4704\n","output_type":"stream"},{"execution_count":131,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7c3282434160>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Classify text with RoBERTa VietNamese","metadata":{}},{"cell_type":"code","source":"# Load the RoBERTa tokenizer and model\nfrom transformers import AutoTokenizer, XLMRobertaForMaskedLM\nroberta_tokenizer = AutoTokenizer.from_pretrained('anhdungitvn/vi-xlm-roberta-large')\nroberta_model = XLMRobertaForMaskedLM.from_pretrained('anhdungitvn/vi-xlm-roberta-large')","metadata":{"execution":{"iopub.status.busy":"2023-05-29T13:30:17.534279Z","iopub.execute_input":"2023-05-29T13:30:17.534959Z","iopub.status.idle":"2023-05-29T15:20:11.657008Z","shell.execute_reply.started":"2023-05-29T13:30:17.534925Z","shell.execute_reply":"2023-05-29T15:20:11.654914Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/456 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b54cd77aa97246f98860b9a96410a7df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/4.55M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae84d5ba1ae04cbbaaf9b44d4012df8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f2e818de3d74435a2346a28676f19d6"}},"metadata":{}},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the training and validation datasets\n\ntrain_dataset,val_dataset = datasets(roberta_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T15:20:12.005335Z","iopub.execute_input":"2023-05-29T15:20:12.005882Z","iopub.status.idle":"2023-05-29T15:20:12.051074Z","shell.execute_reply.started":"2023-05-29T15:20:12.005829Z","shell.execute_reply":"2023-05-29T15:20:12.048368Z"},"trusted":true},"execution_count":16,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define the training and validation datasets\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m train_dataset,val_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m(roberta_tokenizer)\n","\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"],"ename":"NameError","evalue":"name 'datasets' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Define the input shape for the model\nmax_length = 98\n\n# Define the custom top layer for classification\nnum_labels = 7\ntop_layer = tf.keras.layers.Dense(num_labels, activation='softmax')\n\n# Define the RoBERTa model with the custom top layer\ninput_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='input_ids')\nattention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='attention_mask')\nroberta_output = roberta_model({'input_ids': input_ids, 'attention_mask': attention_mask})\nroberta_output = roberta_output.last_hidden_state[:, 0, :]\nroberta_output = top_layer(roberta_output)\nroberta_model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=[roberta_output])\n\nprint(roberta_model.summary())\n\n# Define the loss function and metrics for training\nloss = tf.keras.losses.CategoricalCrossentropy()\nmetrics = [tf.keras.metrics.CategoricalAccuracy()]\noptimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n\n# Compile the RoBERTa model for training\nroberta_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n\n# Train the RoBERTa model on the sentiment analysis task\nroberta_model.fit(train_dataset, epochs=20, validation_data=val_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T15:20:12.054314Z","iopub.status.idle":"2023-05-29T15:20:12.056875Z","shell.execute_reply.started":"2023-05-29T15:20:12.056613Z","shell.execute_reply":"2023-05-29T15:20:12.056640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classify text with GPT-2 ( Transfer Learning )","metadata":{}},{"cell_type":"code","source":"# Load the GPT-2 tokenizer and model\ngpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ngpt2_model = TFGPT2Model.from_pretrained('gpt2')","metadata":{"execution":{"iopub.status.busy":"2023-05-23T02:43:36.777309Z","iopub.execute_input":"2023-05-23T02:43:36.777692Z","iopub.status.idle":"2023-05-23T02:43:55.894604Z","shell.execute_reply.started":"2023-05-23T02:43:36.777663Z","shell.execute_reply":"2023-05-23T02:43:55.893464Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"566c176c0cde44eb967baec0ee9a8a23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5fc84bc365e4594a9441cdbee6a03ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b164ac2eb3a1439b8fdb7638961a0f0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tf_model.h5:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a96e6b10c35644c394e2aa31c699052b"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFGPT2Model.\n\nAll the layers of TFGPT2Model were initialized from the model checkpoint at gpt2.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the training and validation datasets\n\n# Set pad_token\ngpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n\ntrain_dataset,val_dataset = datasets(gpt2_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T02:43:55.897204Z","iopub.execute_input":"2023-05-23T02:43:55.898013Z","iopub.status.idle":"2023-05-23T02:44:01.181478Z","shell.execute_reply.started":"2023-05-23T02:43:55.897952Z","shell.execute_reply":"2023-05-23T02:44:01.180481Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Define the input shape for the model\nmax_length = 98\n\n# Define the custom top layer for classification\nnum_labels = 7\ntop_layer = tf.keras.layers.Dense(num_labels, activation='softmax')\n\n# Define the GPT-2 model with the custom top layer\ninput_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='input_ids')\ngpt2_output = gpt2_model(input_ids)[0]\ngpt2_output = gpt2_output[:, -1, :]\ngpt2_output = top_layer(gpt2_output)\ngpt2_model = tf.keras.models.Model(inputs=input_ids, outputs=gpt2_output)\n\n# Define the loss function and metrics for training\nloss = tf.keras.losses.CategoricalCrossentropy()\nmetrics = [tf.keras.metrics.CategoricalAccuracy()]\noptimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n\n# Compile the GPT-2 model for training\ngpt2_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n\n# Train the GPT-2 model on the sentiment analysis task\ngpt2_model.fit(train_dataset, epochs=30, validation_data=val_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T02:44:01.184032Z","iopub.execute_input":"2023-05-23T02:44:01.184892Z","iopub.status.idle":"2023-05-23T03:46:53.006132Z","shell.execute_reply.started":"2023-05-23T02:44:01.184853Z","shell.execute_reply":"2023-05-23T03:46:53.004998Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['attention_mask'] which did not match any model input. They will be ignored by the model.\n  inputs = self._flatten_to_reference_inputs(inputs)\n","output_type":"stream"},{"name":"stdout","text":"174/174 [==============================] - 157s 651ms/step - loss: 2.2316 - categorical_accuracy: 0.2489 - val_loss: 1.8239 - val_categorical_accuracy: 0.2785\nEpoch 2/30\n174/174 [==============================] - 118s 678ms/step - loss: 1.8173 - categorical_accuracy: 0.2678 - val_loss: 1.8082 - val_categorical_accuracy: 0.2713\nEpoch 3/30\n174/174 [==============================] - 119s 686ms/step - loss: 1.7854 - categorical_accuracy: 0.2763 - val_loss: 1.7738 - val_categorical_accuracy: 0.2828\nEpoch 4/30\n174/174 [==============================] - 119s 682ms/step - loss: 1.7577 - categorical_accuracy: 0.2906 - val_loss: 1.7510 - val_categorical_accuracy: 0.3030\nEpoch 5/30\n174/174 [==============================] - 118s 680ms/step - loss: 1.7504 - categorical_accuracy: 0.2956 - val_loss: 1.7479 - val_categorical_accuracy: 0.2872\nEpoch 6/30\n174/174 [==============================] - 119s 681ms/step - loss: 1.7123 - categorical_accuracy: 0.3198 - val_loss: 1.7197 - val_categorical_accuracy: 0.3420\nEpoch 7/30\n174/174 [==============================] - 119s 683ms/step - loss: 1.6601 - categorical_accuracy: 0.3609 - val_loss: 1.6688 - val_categorical_accuracy: 0.3622\nEpoch 8/30\n174/174 [==============================] - 119s 682ms/step - loss: 1.5936 - categorical_accuracy: 0.3987 - val_loss: 1.5933 - val_categorical_accuracy: 0.3983\nEpoch 9/30\n174/174 [==============================] - 118s 681ms/step - loss: 1.5091 - categorical_accuracy: 0.4319 - val_loss: 1.5823 - val_categorical_accuracy: 0.3896\nEpoch 10/30\n174/174 [==============================] - 118s 680ms/step - loss: 1.4100 - categorical_accuracy: 0.4796 - val_loss: 1.5381 - val_categorical_accuracy: 0.4416\nEpoch 11/30\n174/174 [==============================] - 118s 680ms/step - loss: 1.3215 - categorical_accuracy: 0.5252 - val_loss: 1.4250 - val_categorical_accuracy: 0.4993\nEpoch 12/30\n174/174 [==============================] - 119s 685ms/step - loss: 1.2327 - categorical_accuracy: 0.5503 - val_loss: 1.4891 - val_categorical_accuracy: 0.4863\nEpoch 13/30\n174/174 [==============================] - 119s 683ms/step - loss: 1.1259 - categorical_accuracy: 0.5885 - val_loss: 1.4920 - val_categorical_accuracy: 0.4877\nEpoch 14/30\n174/174 [==============================] - 119s 685ms/step - loss: 1.0345 - categorical_accuracy: 0.6240 - val_loss: 1.5307 - val_categorical_accuracy: 0.4877\nEpoch 15/30\n174/174 [==============================] - 119s 683ms/step - loss: 0.9631 - categorical_accuracy: 0.6550 - val_loss: 1.5780 - val_categorical_accuracy: 0.4704\nEpoch 16/30\n174/174 [==============================] - 118s 680ms/step - loss: 0.8786 - categorical_accuracy: 0.6835 - val_loss: 1.5493 - val_categorical_accuracy: 0.5036\nEpoch 17/30\n174/174 [==============================] - 119s 682ms/step - loss: 0.7884 - categorical_accuracy: 0.7206 - val_loss: 1.6436 - val_categorical_accuracy: 0.4863\nEpoch 18/30\n174/174 [==============================] - 119s 683ms/step - loss: 0.6919 - categorical_accuracy: 0.7518 - val_loss: 1.7124 - val_categorical_accuracy: 0.4646\nEpoch 19/30\n174/174 [==============================] - 119s 685ms/step - loss: 0.6343 - categorical_accuracy: 0.7760 - val_loss: 1.8324 - val_categorical_accuracy: 0.4834\nEpoch 20/30\n174/174 [==============================] - 119s 684ms/step - loss: 0.5728 - categorical_accuracy: 0.7902 - val_loss: 1.8842 - val_categorical_accuracy: 0.4877\nEpoch 21/30\n174/174 [==============================] - 119s 685ms/step - loss: 0.4805 - categorical_accuracy: 0.8284 - val_loss: 2.0793 - val_categorical_accuracy: 0.4906\nEpoch 22/30\n174/174 [==============================] - 119s 686ms/step - loss: 0.4373 - categorical_accuracy: 0.8396 - val_loss: 2.0889 - val_categorical_accuracy: 0.5022\nEpoch 23/30\n174/174 [==============================] - 119s 683ms/step - loss: 0.3614 - categorical_accuracy: 0.8700 - val_loss: 2.2367 - val_categorical_accuracy: 0.4863\nEpoch 24/30\n174/174 [==============================] - 118s 681ms/step - loss: 0.3597 - categorical_accuracy: 0.8715 - val_loss: 2.3268 - val_categorical_accuracy: 0.4574\nEpoch 25/30\n174/174 [==============================] - 118s 680ms/step - loss: 0.2724 - categorical_accuracy: 0.9005 - val_loss: 2.6653 - val_categorical_accuracy: 0.4776\nEpoch 26/30\n174/174 [==============================] - 119s 685ms/step - loss: 0.2542 - categorical_accuracy: 0.9113 - val_loss: 2.5398 - val_categorical_accuracy: 0.4935\nEpoch 27/30\n174/174 [==============================] - 119s 683ms/step - loss: 0.2303 - categorical_accuracy: 0.9162 - val_loss: 2.6942 - val_categorical_accuracy: 0.4834\nEpoch 28/30\n174/174 [==============================] - 119s 681ms/step - loss: 0.2120 - categorical_accuracy: 0.9241 - val_loss: 2.6212 - val_categorical_accuracy: 0.4834\nEpoch 29/30\n174/174 [==============================] - 118s 680ms/step - loss: 0.1745 - categorical_accuracy: 0.9382 - val_loss: 2.8750 - val_categorical_accuracy: 0.4892\nEpoch 30/30\n174/174 [==============================] - 119s 685ms/step - loss: 0.1777 - categorical_accuracy: 0.9357 - val_loss: 2.8517 - val_categorical_accuracy: 0.4949\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7d192846e260>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}